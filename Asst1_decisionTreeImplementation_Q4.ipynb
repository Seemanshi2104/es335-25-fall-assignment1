{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc584dc3",
   "metadata": {},
   "source": [
    "Decision tree Implementation  \n",
    "Q4\n",
    "The complete code is available in experiments.py file.  \n",
    "The overall approach of this code is to analyze the runtime complexity of decision trees experimentally. It does this by generating synthetic datasets of different sizes (varying number of samples N and features M), training and testing a decision tree multiple times to get average training and prediction times, and then plotting how these times scale with N and M. This process is repeated for all four types of decision trees (real/discrete inputs √ó real/discrete outputs), and the results are saved as plots to compare the empirical runtime with theoretical complexity.   \n",
    "  \n",
    "The theoretical training complexity of a decision tree is $O(N \\cdot M \\cdot 2^d)$,  \n",
    "where $N$ is the number of samples, $M$ is the number of features, and $d$ is the maximum depth of the tree. This implies training time grows linearly with $N$ or $M$ (for fixed $d$). In practice, we confirmed this by plotting runtime against N while keeping M=5, and against M while keeping N= 20. Both sets of results showed approximately linear growth, consistent with the theoretical expectation. For testing, the complexity simplifies to O(N‚ãÖd), which depends linearly on the number of test samples but is unaffected by the number of features. The corresponding plots reflect this behavior, showing linear scaling with ùëÅ and remaining essentially flat with respect to ùëÄ.\n",
    "\n",
    "In some cases, the plots are not perfectly straight lines. For instance, the discrete input‚Äìdiscrete output case shows small irregularities. This occurs because the number of nodes in the learned tree is influenced by the data and does not always scale as an exact power of two. Moreover, variations in the computing environment, such as background processes or CPU throttling, can also affect the timing measurements. Nonetheless, the overall shape of the plots supports the theoretical time complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe97d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ce9486",
   "metadata": {},
   "source": [
    "### Real Input Real Output  \n",
    "\n",
    "![My Image](time_complexity_plots/real_input_real_output%20wrt%20N%20Training.png)\n",
    "![My Image](time_complexity_plots/real_input_real_output%20wrt%20M%20Training.png)\n",
    "![My Image](time_complexity_plots/real_input_real_output%20wrt%20N%20Testing.png)\n",
    "![My Image](time_complexity_plots/real_input_real_output%20wrt%20M%20Testing.png)\n",
    "\n",
    "### Real Input Discrete Output  \n",
    "![My Image](time_complexity_plots/real_input_discrete_output%20wrt%20N%20Training.png)\n",
    "![My Image](time_complexity_plots/real_input_discrete_output%20wrt%20M%20Training.png)\n",
    "![My Image](time_complexity_plots/real_input_discrete_output%20wrt%20N%20Testing.png)\n",
    "![My Image](time_complexity_plots/real_input_discrete_output%20wrt%20M%20Testing.png)\n",
    "\n",
    "### Discrete Input Real Output  \n",
    "![My Image](time_complexity_plots/discrete_input_real_output%20wrt%20N%20Training.png)\n",
    "![My Image](time_complexity_plots/discrete_input_real_output%20wrt%20M%20Training.png)\n",
    "![My Image](time_complexity_plots/discrete_input_real_output%20wrt%20N%20Testing.png)\n",
    "![My Image](time_complexity_plots/discrete_input_real_output%20wrt%20M%20Testing.png)\n",
    "\n",
    "### Discrete Input discrete Output  \n",
    "![My Image](time_complexity_plots/discrete_input_discrete_output%20wrt%20N%20Training.png)\n",
    "![My Image](time_complexity_plots/discrete_input_discrete_output%20wrt%20M%20Training.png)\n",
    "![My Image](time_complexity_plots/discrete_input_discrete_output%20wrt%20N%20Testing.png)\n",
    "![My Image](time_complexity_plots/discrete_input_discrete_output%20wrt%20M%20Testing.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be851a",
   "metadata": {},
   "source": [
    "We can observe in all the training plots, there is a roughly linear trend with both N and M and in all the testing plots there is a linear trend with respect to N and constant with respect to M."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d589c8d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
